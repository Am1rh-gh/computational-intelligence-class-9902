{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "semantic-textual-similarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DLo8MLMAag5"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/farbodnm/computational-intelligence-class-9902/blob/main/G10-Semantic-Textual-Similarity/semantic_textual_similarity.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQMEf719zpO4"
      },
      "source": [
        "# Clone from github\n",
        "Clones github repo and moves them for imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJlLhRi220MX",
        "outputId": "9f2427f3-596c-4a2f-97f7-a2fd5e758c38"
      },
      "source": [
        "!git clone https://github.com/farbodnm/computational-intelligence-class-9902.git\n",
        "!mv -v /content/computational-intelligence-class-9902/G10-Semantic-Textual-Similarity/* .\n",
        "!rm -R /content/computational-intelligence-class-9902"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'computational-intelligence-class-9902'...\n",
            "remote: Enumerating objects: 312, done.\u001b[K\n",
            "remote: Counting objects: 100% (312/312), done.\u001b[K\n",
            "remote: Compressing objects: 100% (264/264), done.\u001b[K\n",
            "remote: Total 312 (delta 114), reused 78 (delta 29), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (312/312), 1.98 MiB | 11.77 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n",
            "renamed '/content/computational-intelligence-class-9902/G10-Semantic-Textual-Similarity/data' -> './data'\n",
            "renamed '/content/computational-intelligence-class-9902/G10-Semantic-Textual-Similarity/README.md' -> './README.md'\n",
            "renamed '/content/computational-intelligence-class-9902/G10-Semantic-Textual-Similarity/utils' -> './utils'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-N7Nvns0CFr"
      },
      "source": [
        "# Config\n",
        "Our config for the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ezh3YdnmfAT"
      },
      "source": [
        "config = {\n",
        "    'model':{\n",
        "        'name': 'siamese',\n",
        "        'embed_size': 300,\n",
        "        'batch_size': 1,\n",
        "        'fc_dim': 100,\n",
        "        'embed_mode': 'word',\n",
        "        'learning_rate': 0.00001,\n",
        "        'epochs': 10,\n",
        "        'loss_mode': 'mse',\n",
        "        'optimizer_mode': 'sgd',\n",
        "        'encoder':{\n",
        "            'hidden_size': 100,\n",
        "            'num_layers': 1,\n",
        "            'bidirectional': False,\n",
        "            'dropout': 0.0,\n",
        "        },  \n",
        "    },\n",
        "    'embed_path': './embed.pkl'\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK196FAi0mus"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHJ0z2IbnCPW"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "from utils.tokenizer import reset_word_embedding, reset_char_embedding, load_wordvec, load_charvec, save_vec, change_weights_of_mother\n",
        "from utils.model import Siamese\n",
        "from utils.vocabulary import vocabulary, add_to_vocabulary\n",
        "from data.prepare_data import Dataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyAX4C4t0rtJ"
      },
      "source": [
        "# Data processing.\n",
        "First we start by making a vocabulary of the words in all our sentences.\n",
        "\n",
        "\n",
        "> then we make a vector dictionary for our vocabulary.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h_grIhXtM_U",
        "outputId": "451720f0-b277-4c66-a7c0-e980d9ec3e6f"
      },
      "source": [
        "embed_path = config['embed_path']\n",
        "reset_word_embedding(embed_path)\n",
        "data = Dataset('/content/data/snli_1.0.txt')\n",
        "vocab = vocabulary(data.train_set_pairs())\n",
        "vocab = add_to_vocabulary(data.test_set_pairs(), vocab)\n",
        "vectors = load_wordvec(vocab, embed_path)\n",
        "if len(vectors) == len(vocab):\n",
        "  vocab_size = len(vectors)\n",
        "else:\n",
        "  print('Something is wrong and I can feel it.')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dictionary file created.\n",
            "Made a vocabulary of 13023 words.\n",
            "Made a vocabulary with a total of 13446 words.\n",
            "Loaded 1 already embedded words.\n",
            "Added 13446 new words to the embedding.\n",
            "Loaded 13446 words to our current dictionary\n",
            "Embeddings saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keMnMakcEug-"
      },
      "source": [
        "# Make an embedding\n",
        "Make a weight embedding ordered in the same way our vocabulary is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuy2T6yX2cv1"
      },
      "source": [
        "weights = []\n",
        "for word in vocab:\n",
        "    weights.append(vectors[word])\n",
        "embedding = nn.Embedding(vocab_size, config['model']['embed_size'])\n",
        "weights_matrix = torch.from_numpy(np.array(weights)).type(torch.FloatTensor)\n",
        "embedding.weight = nn.Parameter(weights_matrix, requires_grad = False)\n",
        "\n",
        "config['vocab'] = vocab\n",
        "config['embedding'] = embedding"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR2pxwuMy9bh"
      },
      "source": [
        "Ready our model, loss and optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbdpe_HYFDWH",
        "outputId": "eaa0b5eb-0a5d-4df8-a570-1f33293e6228"
      },
      "source": [
        "siamese = Siamese(config)\n",
        "\n",
        "if config['model']['loss_mode'] == 'cel':\n",
        "  #variable_weight = Variable(torch.FloatTensor([1, 1.125]))\n",
        "  #variable_weight = variable_weight.cuda()\n",
        "  #loss_mode = torch.nn.CrossEntropyLoss(variable_weight)\n",
        "  loss_mode = torch.nn.CrossEntropyLoss()\n",
        "  print('Using CrossEntropyLoss loss,')\n",
        "elif config['model']['loss_mode'] == 'mse':\n",
        "  loss_mode = torch.nn.MSELoss()\n",
        "  print('Using MeanSquaredError loss,')\n",
        "\n",
        "learning_rate = config['model']['learning_rate']\n",
        "if config['model']['optimizer_mode'] == 'sgd':\n",
        "  optimizer = torch.optim.SGD(filter(lambda x: x.requires_grad, siamese.parameters()), lr=learning_rate)\n",
        "  print('and sgd optimizer.')\n",
        "elif config['model']['optimizer_mode'] == 'adam':\n",
        "  optimizer = torch.optim.Adam(filter(lambda x: x.requires_grad, siamese.parameters()), lr=learning_rate)\n",
        "  print('and adam optimizer.')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using MeanSquaredError loss,\n",
            "and sgd optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mKXe1mYzEeS"
      },
      "source": [
        "# Start our training\n",
        "Each epoch we train the model and then use the test dataset to see our progress.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK8mC7nnkzBq",
        "outputId": "7322fbe6-11f9-494f-a546-ac4904cbcd29"
      },
      "source": [
        "current_epoch = 1\n",
        "epoch_num = config['model']['epochs']\n",
        "\n",
        "train_loss_epochs = []\n",
        "test_loss_epochs = []\n",
        "\n",
        "while current_epoch <= epoch_num:\n",
        "\n",
        "  train_loss = []\n",
        "  train_loss_all = []\n",
        "  test_loss_all = []\n",
        "\n",
        "  print('Starting epoch', current_epoch)\n",
        "\n",
        "  for i in range(int(data.train_set_num())):\n",
        "    sentence1 = data.train_set_pairs()[i][0]\n",
        "    sentence2 = data.train_set_pairs()[i][1]\n",
        "    score = data.train_set_scores()[i]\n",
        "\n",
        "    output = siamese(sentence1, sentence2)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if config['model']['loss_mode'] == 'cel':\n",
        "      if score <= 0.5:\n",
        "        score = torch.tensor([0]).long()\n",
        "      if score > 0.5:\n",
        "        score = torch.tensor([1]).long()\n",
        "      output = output.squeeze(0)\n",
        "\n",
        "    elif config['model']['loss_mode'] == 'mse':\n",
        "      score = Variable(torch.tensor(score).type(torch.FloatTensor))\n",
        "      output = output.squeeze(0).squeeze(0).squeeze(0)\n",
        "\n",
        "    #score = score.cuda()\n",
        "    #output = output.cuda()\n",
        "    \n",
        "    loss = loss_mode(output, score)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss.append(loss.data)\n",
        "    train_loss_all.append(loss.data)\n",
        "    #train_loss.append(loss.data.cpu())\n",
        "    #train_loss_all.append(loss.data.cpu())\n",
        "\n",
        "    if ((i + 1) % 2500) == 0:\n",
        "      print(i + 1, 'sentence pairs done, epoch:', current_epoch, 'and current loss:', np.mean(train_loss))\n",
        "      train_loss = []\n",
        "\n",
        "  for j in range(int(data.test_set_num())):\n",
        "    sentence1 = data.test_set_pairs()[j][0]\n",
        "    sentence2 = data.test_set_pairs()[j][1]\n",
        "    score = data.train_set_scores()[j]\n",
        "\n",
        "    output = siamese(sentence1, sentence2)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if config['model']['loss_mode'] == 'cel':\n",
        "      if score <= 0.5:\n",
        "        score = torch.tensor([0]).long()\n",
        "      if score > 0.5:\n",
        "        score = torch.tensor([1]).long()\n",
        "      output = output.squeeze(0)\n",
        "\n",
        "    elif config['model']['loss_mode'] == 'mse':\n",
        "      score = Variable(torch.tensor(score).type(torch.FloatTensor))\n",
        "      output = output.squeeze(0).squeeze(0).squeeze(0)\n",
        "\n",
        "    #score = score.cuda()\n",
        "    #output = output.cuda()\n",
        "\n",
        "    loss = loss_mode(output, score)\n",
        "\n",
        "    test_loss_all.append(loss.data)\n",
        "    #test_loss_all.append(loss.data.cpu())\n",
        "    \n",
        "  print('Epoch', current_epoch, 'train loss:', np.mean(train_loss_all), 'test loss:', np.mean(test_loss_all))\n",
        "  train_loss_epochs.append(np.mean(train_loss_all))\n",
        "  test_loss_epochs.append(np.mean(test_loss_all))\n",
        "  print()\n",
        "\n",
        "  current_epoch += 1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1\n",
            "2500 sentence pairs done, epoch: 1 and current loss: 0.32639435\n",
            "5000 sentence pairs done, epoch: 1 and current loss: 0.27998844\n",
            "7500 sentence pairs done, epoch: 1 and current loss: 0.24354056\n",
            "10000 sentence pairs done, epoch: 1 and current loss: 0.2177415\n",
            "12500 sentence pairs done, epoch: 1 and current loss: 0.19883907\n",
            "15000 sentence pairs done, epoch: 1 and current loss: 0.1891112\n",
            "17500 sentence pairs done, epoch: 1 and current loss: 0.17193526\n",
            "Epoch 1 train loss: 0.23054935 test loss: 0.16990498\n",
            "\n",
            "Starting epoch 2\n",
            "2500 sentence pairs done, epoch: 2 and current loss: 0.1671153\n",
            "5000 sentence pairs done, epoch: 2 and current loss: 0.16424808\n",
            "7500 sentence pairs done, epoch: 2 and current loss: 0.15533654\n",
            "10000 sentence pairs done, epoch: 2 and current loss: 0.15280242\n",
            "12500 sentence pairs done, epoch: 2 and current loss: 0.15105549\n",
            "15000 sentence pairs done, epoch: 2 and current loss: 0.14628604\n",
            "17500 sentence pairs done, epoch: 2 and current loss: 0.14360206\n",
            "Epoch 2 train loss: 0.15401833 test loss: 0.14514817\n",
            "\n",
            "Starting epoch 3\n",
            "2500 sentence pairs done, epoch: 3 and current loss: 0.14631802\n",
            "5000 sentence pairs done, epoch: 3 and current loss: 0.15004449\n",
            "7500 sentence pairs done, epoch: 3 and current loss: 0.14457843\n",
            "10000 sentence pairs done, epoch: 3 and current loss: 0.14525594\n",
            "12500 sentence pairs done, epoch: 3 and current loss: 0.14559259\n",
            "15000 sentence pairs done, epoch: 3 and current loss: 0.14004734\n",
            "17500 sentence pairs done, epoch: 3 and current loss: 0.13973653\n",
            "Epoch 3 train loss: 0.14441825 test loss: 0.1416509\n",
            "\n",
            "Starting epoch 4\n",
            "2500 sentence pairs done, epoch: 4 and current loss: 0.14351901\n",
            "5000 sentence pairs done, epoch: 4 and current loss: 0.14799643\n",
            "7500 sentence pairs done, epoch: 4 and current loss: 0.14313492\n",
            "10000 sentence pairs done, epoch: 4 and current loss: 0.14382567\n",
            "12500 sentence pairs done, epoch: 4 and current loss: 0.14474471\n",
            "15000 sentence pairs done, epoch: 4 and current loss: 0.13854995\n",
            "17500 sentence pairs done, epoch: 4 and current loss: 0.13901602\n",
            "Epoch 4 train loss: 0.14292626 test loss: 0.1411546\n",
            "\n",
            "Starting epoch 5\n",
            "2500 sentence pairs done, epoch: 5 and current loss: 0.14277333\n",
            "5000 sentence pairs done, epoch: 5 and current loss: 0.14744365\n",
            "7500 sentence pairs done, epoch: 5 and current loss: 0.14278325\n",
            "10000 sentence pairs done, epoch: 5 and current loss: 0.14342886\n",
            "12500 sentence pairs done, epoch: 5 and current loss: 0.14455764\n",
            "15000 sentence pairs done, epoch: 5 and current loss: 0.13771722\n",
            "17500 sentence pairs done, epoch: 5 and current loss: 0.13847378\n",
            "Epoch 5 train loss: 0.14241748 test loss: 0.14084041\n",
            "\n",
            "Starting epoch 6\n",
            "2500 sentence pairs done, epoch: 6 and current loss: 0.14241482\n",
            "5000 sentence pairs done, epoch: 6 and current loss: 0.14699946\n",
            "7500 sentence pairs done, epoch: 6 and current loss: 0.14244351\n",
            "10000 sentence pairs done, epoch: 6 and current loss: 0.1432016\n",
            "12500 sentence pairs done, epoch: 6 and current loss: 0.14421996\n",
            "15000 sentence pairs done, epoch: 6 and current loss: 0.13766448\n",
            "17500 sentence pairs done, epoch: 6 and current loss: 0.13828401\n",
            "Epoch 6 train loss: 0.14214209 test loss: 0.14077553\n",
            "\n",
            "Starting epoch 7\n",
            "2500 sentence pairs done, epoch: 7 and current loss: 0.14207657\n",
            "5000 sentence pairs done, epoch: 7 and current loss: 0.14651963\n",
            "7500 sentence pairs done, epoch: 7 and current loss: 0.1422612\n",
            "10000 sentence pairs done, epoch: 7 and current loss: 0.14300197\n",
            "12500 sentence pairs done, epoch: 7 and current loss: 0.14392993\n",
            "15000 sentence pairs done, epoch: 7 and current loss: 0.13736162\n",
            "17500 sentence pairs done, epoch: 7 and current loss: 0.13780369\n",
            "Epoch 7 train loss: 0.14180659 test loss: 0.14080392\n",
            "\n",
            "Starting epoch 8\n",
            "2500 sentence pairs done, epoch: 8 and current loss: 0.14192528\n",
            "5000 sentence pairs done, epoch: 8 and current loss: 0.14619036\n",
            "7500 sentence pairs done, epoch: 8 and current loss: 0.1418028\n",
            "10000 sentence pairs done, epoch: 8 and current loss: 0.1426961\n",
            "12500 sentence pairs done, epoch: 8 and current loss: 0.14365935\n",
            "15000 sentence pairs done, epoch: 8 and current loss: 0.13681813\n",
            "17500 sentence pairs done, epoch: 8 and current loss: 0.1374745\n",
            "Epoch 8 train loss: 0.1414907 test loss: 0.14078656\n",
            "\n",
            "Starting epoch 9\n",
            "2500 sentence pairs done, epoch: 9 and current loss: 0.14165953\n",
            "5000 sentence pairs done, epoch: 9 and current loss: 0.14586228\n",
            "7500 sentence pairs done, epoch: 9 and current loss: 0.14147392\n",
            "10000 sentence pairs done, epoch: 9 and current loss: 0.14221494\n",
            "12500 sentence pairs done, epoch: 9 and current loss: 0.14295052\n",
            "15000 sentence pairs done, epoch: 9 and current loss: 0.13665707\n",
            "17500 sentence pairs done, epoch: 9 and current loss: 0.1371341\n",
            "Epoch 9 train loss: 0.14110538 test loss: 0.14073771\n",
            "\n",
            "Starting epoch 10\n",
            "2500 sentence pairs done, epoch: 10 and current loss: 0.14107789\n",
            "5000 sentence pairs done, epoch: 10 and current loss: 0.14548211\n",
            "7500 sentence pairs done, epoch: 10 and current loss: 0.14135435\n",
            "10000 sentence pairs done, epoch: 10 and current loss: 0.1418379\n",
            "12500 sentence pairs done, epoch: 10 and current loss: 0.14288987\n",
            "15000 sentence pairs done, epoch: 10 and current loss: 0.13626096\n",
            "17500 sentence pairs done, epoch: 10 and current loss: 0.13707963\n",
            "Epoch 10 train loss: 0.14083385 test loss: 0.1403572\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9c5gKj_2xlv"
      },
      "source": [
        "And a train and test loss graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJYohWQL2XFe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b093bd52-eb37-4394-8a27-23f9e84a4981"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('Loss Graph')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_epochs, '-.', color =\"blue\")\n",
        "plt.plot(test_loss_epochs, '-.', color =\"red\")\n",
        "plt.legend(['train loss', 'test loss'], loc =\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}